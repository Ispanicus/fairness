{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoithmic Fairness, Accountability and Ethics\n",
    "## Assignment 2 (Template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folktables import ACSDataSource, BasicProblem, generate_categories\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats.contingency import association\n",
    "from scipy.stats import pointbiserialr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load and Preprocess the data\n",
    "We are going to work with the [Folktables](https://github.com/socialfoundations/folktables#quick-start-examples) dataset (*you have already worked with it*).\n",
    "\n",
    "1. As last week, we are still predicting the *Total person's income*  (I've digitized  it in  `target_transform=lambda x: x > 25000`).\n",
    "2. Today, we are going to implement two methods for data debiasing: [Fair PCA](https://deepai.org/publication/efficient-fair-pca-for-fair-representation-learning) and [A Geometric Solution to Fair Representations](https://dl.acm.org/doi/10.1145/3375627.3375864).\n",
    "3. We are going to evaluate the performance on two sensitive features: `SEX` (i.e. *Males* and *Females*) and `RAC1P` (we will consider only *Whites* and *African-Americans*)\n",
    "4. I updated the filtering method `adult_filter` to keep the specified groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
    "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
    "\n",
    "def adult_filter(data):\n",
    "    \"\"\"Mimic the filters in place for Adult data.\n",
    "    Adult documentation notes: Extraction was done by Barry Becker from\n",
    "    the 1994 Census database. A set of reasonably clean records was extracted\n",
    "    using the following conditions:\n",
    "    ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n",
    "    \"\"\"\n",
    "    df = data\n",
    "    df = df[df['AGEP'] > 16]\n",
    "    df = df[df['PINCP'] > 100]\n",
    "    df = df[df['WKHP'] > 0]\n",
    "    df = df[df['PWGTP'] >= 1]\n",
    "    df = df[df[\"RAC1P\"] < 3] ## keep only Whites and African-Americans\n",
    "    return df\n",
    "\n",
    "\n",
    "ACSIncomeNew = BasicProblem(\n",
    "    features=[\n",
    "        'AGEP', # Age\n",
    "        'COW', # Class of worker i.e private for profit, gov, non-profit\n",
    "        'SCHL', # Education\n",
    "        'MAR', # marriage status\n",
    "        'CIT', # citizenship status\n",
    "        'RELP', # relationship to reference person\n",
    "        'WKHP', # hours worked per week\n",
    "        'PWGTP', # weight\n",
    "        'SEX', # 1. male 2. female\n",
    "        'RAC1P'# 1. white, 2 black\n",
    "    ],\n",
    "    target='PINCP',\n",
    "    target_transform=lambda x: x > 25000,    \n",
    "    group=['SEX', \"RAC1P\"],\n",
    "    preprocess=adult_filter,\n",
    "    postprocess=lambda x: np.nan_to_num(x, -1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features, target, protected = ACSIncomeNew.df_to_pandas(acs_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age and Sex\n",
    "# association(np.array(features[[\"AGEP\",\"SEX\"]], dtype=int))\n",
    "# Sex and age\n",
    "print(\"Sex and Age\",pointbiserialr(features[\"SEX\"]-1, features[\"AGEP\"]))\n",
    "# Sex and school\n",
    "print(\"Sex and school\",pointbiserialr(features[\"SEX\"]-1, features[\"SCHL\"]))\n",
    "# Sex and marriage status\n",
    "print(\"Sex and marriage status cramerv\",round(association(np.array(features[[\"SEX\",\"MAR\"]], dtype=int)),3))\n",
    "# Sex and Work class\n",
    "print(\"Sex and work class cramerv\",round(association(np.array(features[[\"SEX\",\"COW\"]], dtype=int)),3))\n",
    "# Sex and citizenship status\n",
    "print(\"Sex and citizen status cramerv\",round(association(np.array(features[[\"SEX\",\"CIT\"]], dtype=int)),3))\n",
    "# Sex and hours worked per week\n",
    "print(\"Sex and Work Hours\",pointbiserialr(features[\"SEX\"]-1, features[\"WKHP\"]))\n",
    "# Sex and weight\n",
    "print(\"Sex and Weight\",pointbiserialr(features[\"SEX\"]-1, features[\"PWGTP\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, target, protected, test_size=0.3, random_state=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 500\n",
    "\n",
    "X_train = X_train[:N]\n",
    "y_train = y_train[:N]\n",
    "group_train = group_train[:N]\n",
    "X_test = X_test[:N]\n",
    "y_test = y_test[:N]\n",
    "group_test = group_test[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for cat in ['SEX', 'RAC1P']:\n",
    "    for i in range(1,3):\n",
    "        print(f\"{cat} {i} count:\",len(group_train[group_train[cat] == i]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = group_train[group_train['SEX'] == 1]\n",
    "females = group_train[group_train['SEX'] == 2]\n",
    "\n",
    "for i in range(1,3):\n",
    "    print(f\"Male race {i}\", len(males[males['RAC1P'] == i]))\n",
    "    print(f\"Female race {i}\", len(females[females['RAC1P'] == i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Bias in Training Data\n",
    "We find around 10% more men than women in our training data, and more than 11 times more Whites than African-Americans (!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Proxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution of features for each gender, a model could potentially use low weight < ~50 as a proxy variable for woman and a high amount of working hours as a proxy for male."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=X_train.assign(PINCP=y_train), x='PINCP', hue='SEX', multiple=\"dodge\", shrink=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in X_train.drop(['SEX'], axis=1).columns:\n",
    "    sns.histplot(data=X_train, x=feature, hue='SEX', multiple=\"dodge\", shrink=0.8)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "definition_df = data_source.get_definitions(download=True)\n",
    "categories = generate_categories(features=ACSIncomeNew.features, definition_df=definition_df)\n",
    "features, labels, groups = ACSIncomeNew.df_to_pandas(acs_data, categories=categories, dummies=True)\n",
    "### groups now contain information about SEX and RAC1P\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"redundant\" columns\n",
    "features = features.drop([\"RELP_Unmarried partner\",\n",
    "                          \"CIT_U.S. citizen by naturalization\",\n",
    "                          \"SEX_Male\",\n",
    "                          \"SCHL_1 or more years of college credit, no degree\",  \n",
    "                          \"MAR_Divorced\", \n",
    "                          \"RELP_Adopted son or daughter\",\n",
    "                          'COW_Working without pay in family business or farm', \n",
    "                          \"RAC1P_White alone\" ], axis = 1) \n",
    "\n",
    "print(\"Columns with the protected features:\")\n",
    "for i, f in enumerate(features.columns):\n",
    "    if (\"RAC1P\" in f) or (\"SEX\" in f):\n",
    "        print(\"Column ID: %s\" %i, \"(%s)\"%f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features.values, labels.values.reshape(-1), groups, test_size=0.3, random_state=0, shuffle=True)\n",
    "\n",
    "N = 500 ### I am subsampling because it is slow on my machine\n",
    "\n",
    "X_train = X_train[:N]\n",
    "y_train = y_train[:N]\n",
    "group_train = group_train[:N]\n",
    "X_test = X_test[:N]\n",
    "y_test = y_test[:N]\n",
    "group_test = group_test[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# YOUR CODE\n",
    "############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.2.\n",
    "Use the following arguments in the `opt.fmin_funct`: `xtol=1e-4, ftol=1e-4,  maxfun=1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.logspace(1e-5,1e-2,10)\n",
    "###########\n",
    "# YOUR CODE\n",
    "###########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2.3\n",
    "Use the following arguments in the `opt.fmin_funct`: ` xtol=1e-3, ftol=1e-3, approx_grad=True, maxfun=1000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.array([1e-3, 5e-3, 1e-2, 5e-2, 0.1, 1])\n",
    "###########\n",
    "# YOUR CODE\n",
    "###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
